## 单线程的简单优化

#### 优化手法总结

1. 函数尽量写在同一个文件里。
2. 避免在for循环内调用外部函数。
3. 非const指针加上__restrict修饰。
4. 试着用SOA代替AOS。
5. 对齐2的整数幂次字节。
6. 代码尽量简单。
7. 试试#pargma omp simd
8. 循环中的不变量放到外面来。
9. 小循环用#pargma unroll
10. -ffast-math 和-march=native

#### CMAKE中配置方式

```cmake
#开启 -fopennmp
find_package(OpenMP REQUIRED)
target_link_libraries(test PUBLIC OPENMP:OPENMP_CXX)
# 开启-ffast-math 和 -march=native
target_compile_options(test PUBLIC -march=native -ffast-math)
```



### X86汇编

64位x86架构下的通用寄存器有：

**rax,rbx,rcx,rdx, rsi,rdi, rsp,rbp, r8,r9,r10 ... r15**

其中r8到r15是64位x86新增的寄存器，降低了编译器处理寄存器翻车的压力。



**al,ah,ax,eax,rax**都是指向同一块寄存器，区别：

**rax:**寄存器全部**64**位。

**eax:**rax的前**32**位。

**ax:**eax的前**16**位。

**ah:**ax的前**8**位。

**al:**ax的后**8**位。

**函数返回值通过eax传出去。**



**xmm：**

* xmm寄存器有128位宽。
* 可以容纳4个float，或2个double。

#### GCC输出汇编代码的指令

```shell
gcc -fomit-frame-pointer -fverbose-asm -S main.cpp -o /tmp/main.S
```



### AT&T常用汇编指令

```assembly
movl	%esp, %eax	#mov移动指令，l表示32位，	
imull	%esp, %eax	#mul乘法指令，l表示32位，i表示是整数乘法
```

**b表示8位，l表示32位，q表示64位**

#### O3优化

```cpp
int func(int a,int b,int c,int d,int e,int f,int g)
{
    return a+b+c+d+e+f+g;
}
```

**未优化时：**

```assembly
__Z4funciiiiiii:
LFB16:
	.cfi_startproc
 # main.cpp:11:     return a+b+c+d+e+f+g;
	movl	4(%esp), %edx	 # a, tmp89
	movl	8(%esp), %eax	 # b, tmp90
	addl	%eax, %edx	 # tmp90, _1
 # main.cpp:11:     return a+b+c+d+e+f+g;
	movl	12(%esp), %eax	 # c, tmp91
	addl	%eax, %edx	 # tmp91, _2
 # main.cpp:11:     return a+b+c+d+e+f+g;
	movl	16(%esp), %eax	 # d, tmp92
	addl	%eax, %edx	 # tmp92, _3
 # main.cpp:11:     return a+b+c+d+e+f+g;
	movl	20(%esp), %eax	 # e, tmp93
	addl	%eax, %edx	 # tmp93, _4
 # main.cpp:11:     return a+b+c+d+e+f+g;
	movl	24(%esp), %eax	 # f, tmp94
	addl	%eax, %edx	 # tmp94, _5
 # main.cpp:11:     return a+b+c+d+e+f+g;
	movl	28(%esp), %eax	 # g, tmp95
	addl	%edx, %eax	 # _5, _13
 # main.cpp:12: }
	ret	
	.cfi_endproc
```

可以看到，没开优化选项单独时候，函数对于每一个传入的参数，都会先移动到eax寄存器中，做加法计算的时候，也是在edx寄存器中，这样用到了两个寄存器，额外产生了更多的mov操作，十分的麻烦。

**开O3优化时**

```assembly
__Z4funciiiiiii:
LFB18:
	.cfi_startproc
 # main.cpp:11:     return a+b+c+d+e+f+g;
	movl	8(%esp), %eax	 # b, b
	addl	4(%esp), %eax	 # a, tmp96
 # main.cpp:11:     return a+b+c+d+e+f+g;
	addl	12(%esp), %eax	 # c, tmp97
 # main.cpp:11:     return a+b+c+d+e+f+g;
	addl	16(%esp), %eax	 # d, tmp98
 # main.cpp:11:     return a+b+c+d+e+f+g;
	addl	20(%esp), %eax	 # e, tmp99
 # main.cpp:11:     return a+b+c+d+e+f+g;
	addl	24(%esp), %eax	 # f, tmp100
 # main.cpp:11:     return a+b+c+d+e+f+g;
	addl	28(%esp), %eax	 # g, tmp95
 # main.cpp:12: }
	ret	
	.cfi_endproc
```

可以看到，开O3优化后，edx寄存器不见了，编译器直接将位移和相加的操作放在一个寄存器中，省去了很多mov的操作，程序变得更快了。



### SIMD

#### 什么是SIMD

**SIMD(Single-instruction muliple-data)**单指令多数据，他可以大大增加计算密集型程序的吞吐量。

因为SIMD把4个float打包为一个xmm寄存器内运算，很象矢量运算，因此SIMD又称为矢量化操作。

通常认为利用同时处理4个float的SIMD指令可以加速4倍，但是如果算法不适合SIMD,则可能不到四倍，也有因为SIMD让内存访问更加规律，节约指令解码和缓存时间压力等原因，出现加速超过4倍的现象出现。

**来个例子**

xmm寄存器中的加法操作。

addss可以表示

```assembly
addss # 一个float加法
addsd # 一个double加法
addps # 四个float加法
addpd # 两个double加法
```

可以认为如果编译器内有大量ss结尾的指令，说明矢量化失败，如果有大量ps结尾的指令，则说明矢量化成功。 

#### 指针

通常编译器是不会对指针的赋值操作做优化，例子如下：

```cpp
void p_func(int * a,int * b,int *c)
{
    *c = *b;
    *c = *a;
} 
```

开O3优化的情况：

```assembly
__Z6p_funcPiS_S_:
LFB19:
	.cfi_startproc
 # main.cpp:14:     *c = *b;
	movl	8(%esp), %edx	 # b, b
 # main.cpp:13: {
	movl	12(%esp), %eax	 # c, c
 # main.cpp:14:     *c = *b;
	movl	(%edx), %edx	 # *b_4(D), _1
 # main.cpp:14:     *c = *b;
	movl	%edx, (%eax)	 # _1, *c_5(D)
 # main.cpp:15:     *c = *a;
	movl	4(%esp), %edx	 # a, a
	movl	(%edx), %edx	 # *a_7(D), _2
 # main.cpp:15:     *c = *a;
	movl	%edx, (%eax)	 # _2, *c_5(D)
 # main.cpp:16: } 
	ret	
	.cfi_endproc
```

可以看到，想象中编译器应该把*c=\*b优化掉，但是，编译器并没有对指针的赋值操作做任何优化，这是为什么呢？

这是因为有**指针别名的现象**

编译器不能确定c所指的内存和b所指的是不是同一个地址。索性就不优化，一步一步来执行。

那要怎样让编译器大胆对它做优化呢？可以使用__restrict关键字来修饰指针，告诉编译器这些指针比不可能指向同一地址，让编译器可以大胆做优化。

```cpp
void p_func(int *__restrict a,int *__restrict b,int *__restrict c)
{
    *c = *b;
    *c = *a;
} 

```

结果：

```assembly
__Z6p_funcPiS_S_:
LFB19:
	.cfi_startproc
 # main.cpp:15:     *c = *a;
	movl	4(%esp), %eax	 # a, a
	movl	(%eax), %edx	 # *a_5(D), *a_5(D)
	movl	12(%esp), %eax	 # c, c
	movl	%edx, (%eax)	 # *a_5(D), *c_4(D)
 # main.cpp:16: } 
	ret	
	.cfi_endproc
```

只有在写入的时候才会考虑到别名的问题，只读是没影响的，所以__restrict只需加在非const的指针上就好。

```cpp
void p_func(int *const a,int *const b,int *__restrict c)
{
    *c = *b;
    *c = *a;
} 
```

#### 禁止优化：volatile

```cpp
int v_func(int * a)
{
    *a = 42;
    return *a;
}
```

开O3优化：

```assembly
__Z6v_funcPi:
LFB20:
	.cfi_startproc
 # main.cpp:20:     *a = 42;
	movl	4(%esp), %eax	 # a, a
	movl	$42, (%eax)	 #, *a_2(D)
 # main.cpp:22: }
	movl	$42, %eax	 #,
	ret	
	.cfi_endproc
```

可以看到，编译器直接将42返回了，但是若是在多线程中，

```cpp
*a = 42;
return *a;
```

这两句之间可能会有其他线程将*a的值改变，从而导致返回的不是42，因此我们要防止编译器做出这类优化导致程序出错，这个时候就要加上volatile修饰，告诉编译器不要对这个指针做优化。

```cpp
int v_func(int volatile * a)
{
    *a = 42;
    return *a;
}
```

可以看到编译器按照原来的指令逐句翻译执行，返回的是正常的*a的结果。

```assembly
__Z6v_funcPVi:
LFB20:
	.cfi_startproc
 # main.cpp:19: {
	movl	4(%esp), %eax	 # a, a
 # main.cpp:20:     *a = 42;
	movl	$42, (%eax)	 #, *a_2(D)
 # main.cpp:21:     return *a;
	movl	(%eax), %eax	 # *a_2(D), <retval>
 # main.cpp:22: }
	ret	
	.cfi_endproc
```

#### 合并写入

```cpp
void v_func(int * a)
{
    a[0] = 111;
    a[1] = 222;
    a[2] = 333;
    a[3] = 444;
}
```

可以看到，在开启O3优化的情况下，四个int32可以合并成__m128,用上了

vmovaps，vmovups等指令写入xmm寄存器，来实现读写优化。

```assembly
__Z6v_funcPi:
LFB20:
	.cfi_startproc
 # main.cpp:20:     a[0] = 111;
	vmovaps	LC0, %xmm0	 #, tmp83
 # main.cpp:19: {
	pushl	%ebp	 #
	.cfi_def_cfa_offset 8
	.cfi_offset 5, -8
	movl	%esp, %ebp	 #,
	.cfi_def_cfa_register 5
 # main.cpp:20:     a[0] = 111;
	movl	8(%ebp), %eax	 # a, a
	vmovups	%xmm0, (%eax)	 # tmp83, MEM[(int *)a_2(D)]
 # main.cpp:24: }
	popl	%ebp	 #
	.cfi_restore 5
	.cfi_def_cfa 4, 4
	ret	
	.cfi_endproc
LFE20:
	.section .rdata,"dr"
	.align 16
LC0:
	.long	111
	.long	222
	.long	333
	.long	444
	.ident	"GCC: (MinGW.org GCC Build-2) 9.2.0"

```

**两个32位合并为64位写入rax**

**四个32位合并为128位写入xmm**

**八个32位合并为256位写入ymm**

**注意：**不是所有的64位电脑都有ymm寄存器，所以它不敢保证运行这个程序的电脑支持AVX指令集，因此即使是开O3优化，默认依然不会写入ymm。

这个时候只要编译的时候加上 -march=native的参数，编译器就会根据正在运行的电脑检测是否使用AVX指令集来编译，但是这样的话，编译出的程序就不能在不支持AVX指令集的电脑上跑了。

 ```cpp
 void v_func(int * a)
 {
     a[0] = 111;
     a[1] = 222;
     a[2] = 333;
     a[3] = 444;
     a[4] = 111;
     a[5] = 222;
     a[6] = 333;
     a[7] = 444;
 }
 ```

```assembly
__Z6v_funcPi:
LFB20:
	.cfi_startproc
 # main.cpp:20:     a[0] = 111;
	vmovdqa	LC0, %ymm0	 #, tmp83
 # main.cpp:19: {
	pushl	%ebp	 #
	.cfi_def_cfa_offset 8
	.cfi_offset 5, -8
	movl	%esp, %ebp	 #,
	.cfi_def_cfa_register 5
 # main.cpp:20:     a[0] = 111;
	movl	8(%ebp), %eax	 # a, a
	vmovdqu	%ymm0, (%eax)	 # tmp83, MEM[(int *)a_2(D)]
	vzeroupper
 # main.cpp:29: }
	popl	%ebp	 #
	.cfi_restore 5
	.cfi_def_cfa 4, 4
	ret	
	.cfi_endproc
LFE20:
	.section .rdata,"dr"
	.align 32
LC0:
	.long	111
	.long	222
	.long	333
	.long	444
	.long	111
	.long	222
	.long	333
	.long	444
	.ident	"GCC: (MinGW.org GCC Build-2) 9.2.0"

```

**SIMD加速**

```cpp
void v_func(int * a)
{
    for (int i = 0; i < 1024;i++)
    {
        a[i] = i;
    }
}
```

对于上面这样的指令，编译器会利用SIMD来进行优化。

```assembly
__Z6v_funcPi:
LFB20:
	.cfi_startproc
	vmovdqa	LC0, %ymm0	 #, vect_vec_iv_.13
	vmovdqa	LC1, %ymm2	 #, tmp89
	pushl	%ebp	 #
	.cfi_def_cfa_offset 8
	.cfi_offset 5, -8
	movl	%esp, %ebp	 #,
	.cfi_def_cfa_register 5
	movl	8(%ebp), %eax	 # a, ivtmp.19
	leal	4096(%eax), %edx	 #, _9
	.p2align 4
	.p2align 3
L6:
	vmovdqa	%ymm0, %ymm1	 # vect_vec_iv_.13, vect_vec_iv_.13
	addl	$32, %eax	 #, ivtmp.19
	vpaddd	%ymm2, %ymm0, %ymm0	 # tmp89, vect_vec_iv_.13, vect_vec_iv_.13
 # main.cpp:22:         a[i] = i;
	vmovdqu	%ymm1, -32(%eax)	 # vect_vec_iv_.13, MEM[base: _2, offset: 0B]
	cmpl	%eax, %edx	 # ivtmp.19, _9
	jne	L6	 #,
	vzeroupper
 # main.cpp:24: }
	popl	%ebp	 #
	.cfi_restore 5
	.cfi_def_cfa 4, 4
	ret	
	.cfi_endproc
LFE20:
	.section .rdata,"dr"
	.align 32
LC0:
	.long	0
	.long	1
	.long	2
	.long	3
	.long	4
	.long	5
	.long	6
	.long	7
	.align 32
LC1:
	.long	8
	.long	8
	.long	8
	.long	8
	.long	8
	.long	8
	.long	8
	.long	8
	.ident	"GCC: (MinGW.org GCC Build-2) 9.2.0"
```

解释一下，它的写入是8个int32合并成一个_m256写入ymm，也就是说将1024个数字每8个分成一组，一次写入8个int，一次计算8个int的加法，只循环1024/8次从而更加高效。

那如果不是写入1024个，而是写入1025怎么办呢，这个时候编译器就会采用边界特判法，前1024个使用SIMD指令输入，余下的就就用传统的标量填入的方式写入，从而能对大量的数据矢量化处理。

### 循环

循环中的矢量化：编译器要伺候指针别名的情况。

```cpp
void p_func(float* a,float * b)
{
    for (int i = 0; i < 1024;i++)
        a[i] = b[i] + 1;
} 
```

```assembly
__Z6p_funcPfS_:
LFB0:
	.cfi_startproc
	pushl	%ebp	 #
	.cfi_def_cfa_offset 8
	.cfi_offset 5, -8
	movl	%esp, %ebp	 #,
	.cfi_def_cfa_register 5
 # main.cpp:3: {
	movl	12(%ebp), %ecx	 # b, b
	movl	8(%ebp), %edx	 # a, a
	leal	31(%ecx), %eax	 #, tmp94
	subl	%edx, %eax	 # a, tmp95
	cmpl	$62, %eax	 #, tmp95
 # main.cpp:4:     for (int i = 0; i < 1024;i++)
	movl	$0, %eax	 #, i
	jbe	L2	 #,
	vmovaps	LC0, %ymm1	 #, tmp102
	.p2align 4
	.p2align 3
L4:
 # main.cpp:5:         a[i] = b[i] + 1;
	vaddps	(%ecx,%eax), %ymm1, %ymm0	 # MEM[base: b_10(D), index: ivtmp.22_1, offset: 0B], tmp102, vect__6.8
 # main.cpp:5:         a[i] = b[i] + 1;
	vmovups	%ymm0, (%edx,%eax)	 # vect__6.8, MEM[base: a_11(D), index: ivtmp.22_1, offset: 0B]
	addl	$32, %eax	 #, ivtmp.22
	cmpl	$4096, %eax	 #, ivtmp.22
	jne	L4	 #,
	vzeroupper
L10:
 # main.cpp:6: } 
	popl	%ebp	 #
	.cfi_remember_state
	.cfi_restore 5
	.cfi_def_cfa 4, 4
	ret	
	.p2align 4
	.p2align 3
L2:
	.cfi_restore_state
 # main.cpp:5:         a[i] = b[i] + 1;
	fld1	
	fadds	(%ecx,%eax,4)	 # MEM[base: b_10(D), index: _24, step: 4, offset: 0B]
 # main.cpp:5:         a[i] = b[i] + 1;
	fstps	(%edx,%eax,4)	 # MEM[base: a_11(D), index: _24, step: 4, offset: 0B]
 # main.cpp:4:     for (int i = 0; i < 1024;i++)
	incl	%eax	 # i
 # main.cpp:4:     for (int i = 0; i < 1024;i++)
	cmpl	$1024, %eax	 #, i
	je	L10	 #,
 # main.cpp:5:         a[i] = b[i] + 1;
	fld1	
	fadds	(%ecx,%eax,4)	 # MEM[base: b_10(D), index: _24, step: 4, offset: 0B]
 # main.cpp:5:         a[i] = b[i] + 1;
	fstps	(%edx,%eax,4)	 # MEM[base: a_11(D), index: _24, step: 4, offset: 0B]
 # main.cpp:4:     for (int i = 0; i < 1024;i++)
	incl	%eax	 # i
 # main.cpp:4:     for (int i = 0; i < 1024;i++)
	cmpl	$1024, %eax	 #, i
	jne	L2	 #,
	jmp	L10	 #
	.cfi_endproc
LFE0:
	.section .rdata,"dr"
	.align 32
LC0:
	.long	1065353216
	.long	1065353216
	.long	1065353216
	.long	1065353216
	.long	1065353216
	.long	1065353216
	.long	1065353216
	.long	1065353216
	.ident	"GCC: (MinGW.org GCC Build-2) 9.2.0"
```

可以看到，编译器为了防止出现指针别名的情况出现，即a数组和b数组有部分地方是重合的情况，它生成了两个版本的汇编代码，分别是SIMD矢量化的和传统标量的代码。

解释一下这段汇编，考虑到func(a,a+1)的情况，在运行的时候，先检测a，b指针的差值是否超过1024来判断是否有重叠现象。

* 若是没有，则跳转到SIMD版本高效运行。
* 若是没有，则跳转到矢量版本低效运行，防止出错。

加上__restrict修饰指针，告诉编译器这两个数组不会重合，编译器就只会生成并运行SIMD版本。

**除了用__restrict以外，还可以用OpenMP语句。**

#### OpenMP

OpenMP是gcc特有的高性能计算的框架，使用OpenMP可以开启强制矢量化的操作。

在函数内加一条**#param omp simd**

```cpp
void p_func(float* a,float * b)
{
# pragma omp simd
    for (int i = 0; i < 1024;i++)
        a[i] = b[i] + 1;
} 
```

添加编译指令**-fopenmp**

就可以得到只有SIMD的代码。

```assembly
__Z6p_funcPfS_:
LFB0:
	.cfi_startproc
	vmovaps	LC0, %ymm1	 #, tmp90
	pushl	%ebp	 #
	.cfi_def_cfa_offset 8
	.cfi_offset 5, -8
	xorl	%eax, %eax	 # ivtmp.13
	movl	%esp, %ebp	 #,
	.cfi_def_cfa_register 5
 # main.cpp:3: {
	movl	8(%ebp), %ecx	 # a, a
	movl	12(%ebp), %edx	 # b, b
	.p2align 4
	.p2align 3
L2:
 # main.cpp:6:         a[i] = b[i] + 1;
	vaddps	(%edx,%eax), %ymm1, %ymm0	 # MEM[base: b_10(D), index: ivtmp.13_24, offset: 0B], tmp90, vect__6.8
 # main.cpp:6:         a[i] = b[i] + 1;
	vmovups	%ymm0, (%ecx,%eax)	 # vect__6.8, MEM[base: a_11(D), index: ivtmp.13_24, offset: 0B]
	addl	$32, %eax	 #, ivtmp.13
	cmpl	$4096, %eax	 #, ivtmp.13
	jne	L2	 #,
	vzeroupper
 # main.cpp:7: } 
	popl	%ebp	 #
	.cfi_restore 5
	.cfi_def_cfa 4, 4
	ret	
	.cfi_endproc
LFE0:
	.section .rdata,"dr"
	.align 32
LC0:
	.long	1065353216
	.long	1065353216
	.long	1065353216
	.long	1065353216
	.long	1065353216
	.long	1065353216
	.long	1065353216
	.long	1065353216
	.ident	"GCC: (MinGW.org GCC Build-2) 9.2.0"
```

#### 循环中的if语句

若是if在循环中，编译器没法做矢量化优化，因此编译器会将if提取到循环外面来，先判断循环再矢量化。

```cpp
void p_func(float* a,float * b,bool is_mul)
{
# pragma omp simd
    for (int i = 0; i < 1024;i++)
        if(is_mul)
            a[i] = a[i] * b[i];
        else
            a[i] = a[i] + b[i];
} 
```

```assembly
__Z6p_funcPfS_b:
LFB0:
	.cfi_startproc
	pushl	%ebp	 #
	.cfi_def_cfa_offset 8
	.cfi_offset 5, -8
	xorl	%eax, %eax	 # ivtmp.29
	movl	%esp, %ebp	 #,
	.cfi_def_cfa_register 5
	cmpb	$0, 16(%ebp)	 #, is_mul
 # main.cpp:3: {
	movl	8(%ebp), %edx	 # a, a
	movl	12(%ebp), %ecx	 # b, b
	jne	L2	 #,
	.p2align 4
	.p2align 3
L3:
 # main.cpp:9:             a[i] = a[i] + b[i];
	vmovups	(%ecx,%eax), %ymm1	 # MEM[base: b_21(D), index: ivtmp.29_9, offset: 0B], tmp101
	vaddps	(%edx,%eax), %ymm1, %ymm0	 # MEM[base: a_20(D), index: ivtmp.29_9, offset: 0B], tmp101, vect__25.15
 # main.cpp:9:             a[i] = a[i] + b[i];
	vmovups	%ymm0, (%edx,%eax)	 # vect__25.15, MEM[base: a_20(D), index: ivtmp.29_9, offset: 0B]
	addl	$32, %eax	 #, ivtmp.29
	cmpl	$4096, %eax	 #, ivtmp.29
	jne	L3	 #,
L8:
	vzeroupper
 # main.cpp:10: } 
	popl	%ebp	 #
	.cfi_remember_state
	.cfi_restore 5
	.cfi_def_cfa 4, 4
	ret	
	.p2align 4
	.p2align 3
L2:
	.cfi_restore_state
 # main.cpp:7:             a[i] = a[i] * b[i];
	vmovups	(%edx,%eax), %ymm2	 # MEM[base: a_20(D), index: ivtmp.37_29, offset: 0B], tmp102
	vmulps	(%ecx,%eax), %ymm2, %ymm0	 # MEM[base: b_21(D), index: ivtmp.37_29, offset: 0B], tmp102, vect__7.24
 # main.cpp:7:             a[i] = a[i] * b[i];
	vmovups	%ymm0, (%edx,%eax)	 # vect__7.24, MEM[base: a_20(D), index: ivtmp.37_29, offset: 0B]
	addl	$32, %eax	 #, ivtmp.37
	cmpl	$4096, %eax	 #, ivtmp.37
	jne	L2	 #,
	jmp	L8	 #
	.cfi_endproc
LFE0:
	.ident	"GCC: (MinGW.org GCC Build-2) 9.2.0"
```

编译器生成的代码类似于：

```cpp
void p_func(float* a,float * b,bool is_mul)
{
# pragma omp simd
    if(is_mul)
        for (int i = 0; i < 1024;i++)
            `a[i] = a[i] * b[i];
    else
        for (int i = 0; i < 1024;i++)
            a[i] = a[i] + b[i];
} 
```



### 对齐

我们常用到这样的代码

```cpp
struct vec2
{
    float x;
    float y;
};
void p_func(vec2 *a, vec2 *b)
{
# pragma omp simd
    for (int i = 0; i < 1024;i++)
            a[i].x = a[i].x + b[i].x;
} 
```

因为vec2为64位，因此编译器可以很方便进行优化，生成SIMD的操作指令。

但是若是写成3维向量。

```cpp
struct vec3
{
    float x;
    float y;
    float z;
};
```

编译器就不好优化了，因为3个32位的不好进行矢量化操作，所以这时候我们只需要让这个结构体对齐128字节就好。

要怎么做呢？

```cpp
struct vec3
{
    float x;
    float y;
    float z;
    char padding[4];//直接加四个无意义的字符对齐。
};

struct alignas(16) vec3//使用alignas语法，要求编译器将此结构体对齐16字节。
{
    float x;
    float y;
    float z;
};
```

但是对齐之后虽然计算速度变快了，但是对于内存io的压力加大了，而且访问数据也是在数组内跳跃式的访问，实际上不一定速度变快。

更合理的方案是优化数据排布的方式，这里有一种面向数据的编程思想。

对于1024个vec3，我们有两种存储方案。

##### AOS（Array of Struct）

**AOS:单个对象的属性紧挨着存储。**类似于xyzxyz...这样的存储方式，代码为

```cpp
struct vec3
{
    float x;
    float y;
    float z;
    char padding[4];//直接加四个无意义的字符对齐。
};
vec3 v[1024];
```

**优点：**这是一种面向对象的编程思想，十分直观。

​			可以存储在复杂的数据结构中，如map，

**缺点：**但是不利于cpu的SIMD数据处理，而且必须对齐为2的整数幂次才高效。



##### SOA（Struct of Array）

**SOA:属性分离存储在多个数组中。**代码为

```cpp
struct vec3
{
    float x[1024];
    float y[1024];
    float z[1024];
};
vec3 v;
```

**优点：**属性分开存储，批量运算时方便SIMD优化。

​			数据的访问和运算是连续的，对CPU友好。 

​			不需要对齐。

**缺点：**不符合直觉

### 自动调用标准库

```cpp
void clear(int *a,int n)
{
    for (int i = 0; i < n;i++)
        a[i] = 0;
}
```

```assembly
__Z5clearPii:
LFB21:
	.cfi_startproc
	subl	$28, %esp	 #,
	.cfi_def_cfa_offset 32
 # main.cpp:31: {
	movl	36(%esp), %eax	 # n, n
 # main.cpp:32:     for (int i = 0; i < n;i++)
	testl	%eax, %eax	 # n
	jle	L9	 #,
 # main.cpp:33:         a[i] = 0;
	sall	$2, %eax	 #, tmp86
	movl	$0, 4(%esp)	 #,
	movl	%eax, 8(%esp)	 # tmp86,
	movl	32(%esp), %eax	 # a, a
	movl	%eax, (%esp)	 # a,
	call	_memset	 #
L9:
 # main.cpp:34: }
	addl	$28, %esp	 #,
	.cfi_def_cfa_offset 4
	ret	
	.cfi_endproc
```

可以看到，编译器没有一个一个的置零，而是call了一个_memset的外部函数，因为一般标准库内的实现是更加高效的，memcpy也是同理。
